---
title: Moissonnage du Web avec R
slug: webscrapingfr
execute:
  cache: false
  error: true
format: hugo-md
---

**16 février 2023, 13h30 à 14h50 HNE**

**Présenté par**: Pier-Luc St-Onge

**Durée**: 80 minutes

**Description**: Internet est non seulement un trésor riche en informations, mais une grande portion y est
accessible publiquement, ce qui est propice à une utilisation pour la recherche. Cependant, extraire
l’information de pages Web et la formater pour analyse peut rapidement devenir une tâche fastidieuse. Les
outils de moissonnage du Web permettent d’automatiser en partie ce processus et le langage R est populaire
pour réaliser cette tâche. Dans cet atelier, nous allons donc vous guider à travers un exemple simple
utilisant le module rvest.

Inscrivez-vous [ici](https://www.eventbrite.ca/e/512943125697){target="_blank"}

The same workshop [in English](/webscraping).

#### Biographie

Diplômé au baccalauréat et à la maîtrise en génie logiciel et génie informatique, **Pier-Luc St-Onge** a
travaillé pendant cinq ans pour différents laboratoires de recherche avant de rejoindre Calcul Québec en
mai 2013. Dans son projet de recherche, il s’était spécialisé en vision par ordinateur avec OpenCV. À Calcul
Québec, il fait partie de l’équipe d’analystes offrant du soutien aux utilisateurs des ressources de calcul.

<!-- {{< vimeo 690948795 >}} -->
<!-- <br> -->

<!-- - [Watch this session on Vimeo](https://vimeo.com/690948795) -->

{{<br>}}

-----

## À propos

Le matériel ci-dessous est une traduction et adaptation du matériel original
[*Web scraping with R*](https://mint.westdri.ca/r/webscraping.html){target="_blank"}
de Marie-Hélène Burle sur le
[site d'ateliers de WestDRI](https://mint.westdri.ca/){target="_blank"}.

Pour cet atelier, nous allons utiliser un serveur RStudio éphémère.
Pour y accéder, il faut se connecter à un portail JupyterHub;
les détails sont donnés en atelier.

Le serveur RStudio est déjà configuré avec les deux modules suivants :

* [rvest](https://cran.r-project.org/web/packages/rvest/index.html){target="_blank"}
* [tibble](https://cran.r-project.org/web/packages/tibble/index.html){target="_blank"}

Si vous préférez exécuter les exemples sur votre propre ordinateur,
vous devez les installer avec `install.packages()`.

## Introduction

### HTML et CSS

Le [*HyperText Markup Language*](https://fr.wikipedia.org/wiki/Hypertext_Markup_Language){target="_blank"}
(ou HTML) est le langage de balisage standard pour représenter des pages Web.
Il permet, entre autres, d'encoder la structure d'une page Web et
le formatage de son contenu.
Pour ce qui est des règles de formatage réutilisées par plusieurs
pages HTML, il est possible de les sauvegarder dans des fichiers
[*Cascading Style Sheets*](https://fr.wikipedia.org/wiki/Feuilles_de_style_en_cascade){target="_blank"}
(ou CSS).

Le HTML utilise des balises de la forme suivante :

```{.html}
<balise>Du contenu</balise>
```

Certaines balises ont aussi des attributs :

```{.html}
<balise nom_attribut="valeur attribut">Du contenu</balise>
```

{{<ex>}}
Exemples réels :
{{</ex>}}

Structure du site :

```{.html}
<h2 id="ancre">Ceci est un titre de niveau 2</h2>
<p>Ceci est un paragraphe. Cliquez ce
  <a href="https://une.adresse/page.html#ancre">lien</a>.
</p>
```

Formatage :

```{.html}
<p class="texte_rouge">
  <strong>Pour du texte en caractères gras</strong>
</p>
```

### Moissonnage du Web

Le moissonnage du Web consiste à utiliser un ensemble d'outils afin
d'extraire automatiquement de l'information directement d'Internet.

Alors que la plupart des données sur Internet sont disponibles
publiquement, il peut être illégal de moissonner certains sites.
En effet, vous devriez toujours regarder la politique d'utilisation d'un
site Web avant de tenter toute extraction d'information par moissonnage.
Notez aussi que certains sites peuvent vous bloquer si vous leur envoyez
un trop grand nombre de requêtes HTTP dans une courte période de temps.
Par conséquent, si vous planifiez effectuer du moissonnage à grande
échelle, vous devriez considérer l'utilisation du module R
[`polite`](https://dmi3kno.github.io/polite/){target="_blank"}.

### Un site Web en exemple

Nous allons utiliser
[**ce site Web**](https://trace.tennessee.edu/utk_graddiss/index.html){target="_blank"}
de [l'Université du Tennessee](https://www.utk.edu/){target="_blank"},
car il présente une interface de base de données
dont le code HTML est facile à décortiquer.
**Notre objectif consiste donc à extraire de ce site la date de publication,
le département de recherche et le nom du directeur ou de la directrice de
recherche pour chacune des thèses de doctorat de cette université.**
Ces informations doivent ensuite être colligées dans un *data frame*.

> Note : pour cet atelier, nous nous limiterons à la première
  page qui contient les liens des 100 thèses les plus récentes.
  Si vous vouliez extraire les données de toutes les thèses, il vous
  faudrait envoyer une requête HTTP pour chaque page de la base de données.

## Méthodologie

Avant de se lancer dans la programmation, il est recommandé
de réfléchir aux grandes étapes de notre moissonnage.
Étant donné la structure du site Web, la création du *data frame* avec
les données des thèses de la première page se fera en deux étapes :

1. À partir de
  [la première page](https://trace.tennessee.edu/utk_graddiss/index.html){target="_blank"}
  de la base de données, nous voulons colliger une liste
  d'hyperliens menant vers les pages de chaque thèse.
2. Avec ces hyperliens, nous voulons moissonner les pages
  correspondantes afin d'y extraire la valeur des champs
  *Date of Award*, *Major* et *Major Professor* de chaque thèse.

### Utiliser un module R spécialisé

Pour les deux grandes étapes ci-dessus, nous allons utiliser le module R
[`rvest`](https://cran.r-project.org/web/packages/rvest/index.html){target="_blank"}
qui fait partie du [tidyverse](https://www.tidyverse.org/){target="_blank"},
un ensemble moderne de modules R.
Il s'agit d'un module influencé par le populaire module Python
[Beautiful Soup](https://en.wikipedia.org/wiki/Beautiful_Soup_(HTML_parser)){target="_blank"}
et qui facilite le moissonnage du Web via le langage R.

Chargeons-le dans notre session R :

```{r}
library(rvest)
```

### Obtenir les données HTML brutes

Tel que mentionné ci-dessus, notre site en exemple est la
[base de données de thèses de doctorat](https://trace.tennessee.edu/utk_graddiss/index.html){target="_blank"}
de l'Université du Tennessee.

Assignons l'adresse du site (une chaîne de caractères) à une variable :

```{r}
adresse <- "https://trace.tennessee.edu/utk_graddiss/index.html"
```

L'étape suivante consiste à obtenir les données HTML de cette page :

```{r}
html <- read_html(adresse)
```

Regardons un aperçu de ces données HTML encore à l'état brut :

```{r}
html
```

## Extraction des données pertinentes

### Inspection du code HTML

Le code HTML contient bel et bien les données qui nous intéressent,
mais elles sont mélangées avec plusieurs balises HTML, des instructions
de formatage et d'autres données inutiles pour notre objectif.
Nous devons donc extraire ces données et les regrouper dans un format pratique.

La première étape consiste à trouver les branches de balises,
souvent enrichies de [sélecteurs CSS](#points-à-retenir),
qui contiennent les données que nous voulons.
Pour ce faire, vous pouvez utiliser l'inspecteur intégré
de votre navigateur Web sur la page de thèses.
Par exemple, en pointant un hyperlien avec la souris :

* **Firefox** : bouton droit de la souris et *Inspecter*
  * L'arborescence se trouve au bas de la fenêtre
* **Google Chrome** : bouton droit de la souris et *Inspecter*
  * L'arborescence se trouve à la droite de la fenêtre
* **Microsoft Edge** : bouton droit de la souris et *Inspecter*
  * L'arborescence se trouve à la droite de la fenêtre
* **Safari** : bouton droit de la souris et *Inspecter l'élément*
  * Note: il faut au préalable activer le menu *Développement* dans les
    paramètres avancés.

> Voir aussi le [SelectorGadget](https://selectorgadget.com/){target="_blank"}.

On remarque donc que toutes les adresses qui nous intéressent se trouvent
dans l'attribut `href` des balises `<a>` qui sont elles-même dans des
paragraphes `<p>` dont la classe CSS porte le nom `article-listing`.

### Extraction d'une seule adresse

Puisqu'il est recommandé de tester l'extraction d'information sur
un seul élément avant d'effectuer un moissonnage sur toute la page,
essayons uniquement d'obtenir l'adresse de la première thèse.

La fonction `html_element()` du module `rvest` retourne le premier
élément HTML qui correspond aux sélecteurs CSS donnés en paramètre.
Pour les paragraphes `<p>` de classe `article-listing`, nous ferons une
recherche avec `p.article-listing` et sauvegarderons le résultat dans `test`.

```{r}
test <- html %>% html_element("p.article-listing")
```

> Note : `%>%` est un opérateur de redirection du module tidyverse
  [magrittr](https://magrittr.tidyverse.org/){target="_blank"}.
  Cet opérateur transmet l'objet résultant de l'expression de gauche
  à l'appel de fonction de droite comme premier argument.
  En fait, nous aurions pu écrire `html_element(html, "p.article-listing")`,
  mais l'opérateur `%>%` permet d'enchaîner élégamment
  plusieurs appels similaires.

Le nouvel objet retourné par `html_element()` est une liste d'un seul élément :

```{r}
typeof(test)
```

Affichons-la :

```{r}
test
```

L'adresse voulue s'y trouve, donc nous avons isolé le bon élément.
Cependant, nous devons poursuivre le nettoyage de notre extraction.

Comme vous pouvez le voir dans l'affichage de `test`,
l'adresse se trouve dans un élément `<a>`.
Utilisons à nouveau `html_element()`, mais avec `"a"` seulement :

```{r}
test_a <- test %>% html_element("a")
test_a
```

> Note : nous aurions pu utiliser la fonction `html_children()`
  pour aller chercher les éléments enfant du paragraphe :
  `test %>% html_children()`.
  Par contre, il y a un risque d'obtenir une liste de plusieurs éléments.

Finalement, à partir de ce dernier objet,
nous pouvons extraire la valeur de l'attribut `href` :

```{r}
test_addr <- test_a %>% html_attr("href")
test_addr
```

C'est bien l'adresse voulue et elle est stockée en mémoire
sous la forme d'une chaîne de caractères, ce qui est parfait!

### Extraire les données de la page de thèse

Maintenant que nous avons l'adresse de la page d'information de la
première thèse, nous voulons extraire la date de publication, le département
de recherche et le nom du directeur ou de la directrice de recherche.

Nous venons de voir que `test_addr` est une chaîne de caractères
représentant une adresse et nous savons comment l'utiliser.
Comme nous avions fait pour la page de la base de données, nous allons
lire les données HTML brutes et les assigner à une nouvelle variable :

```{r}
test_html <- read_html(test_addr)
test_html
```

Maintenant, nous voulons extraire la date de publication :

* Celle-ci se trouve dans une balise `<p>` dont le parent est identifié par
  `#publication_date`. Or, la syntaxe du sélecteur nous permet d'isoler
  directement le paragraphe enfant en utilisant `#publication_date p`.
* Ensuite, à partir de la sortie de `html_element()`,
  au lieu d'aller chercher la valeur d'un attribut,
  nous voulons plutôt extraire le texte de notre paragraphe.
  Dans ce cas, nous devons utiliser la fonction `html_text2()` qui
  extrait le texte et ajoute des sauts de ligne `\n` lorsque requis.

```{r}
test_date <- test_html %>% html_element("#publication_date p") %>% html_text2()
```

> Note : dans la page de la base de données, si nous avions utilisé
  `html_text2()` au lieu de `html_attr("href")`, nous aurions eu
  le texte de l'hyperlien, c'est-à-dire le titre de la thèse.

Vérifions maintenant le contenu de notre date (de format `"M-AAAA"`) :

```{r}
test_date
```

Nous pouvons utiliser la même méthode pour extraire le département de
recherche, sauf que nous devons utiliser le sélecteur `#department p` :

```{r}
test_department <- test_html %>% html_element("#department p") %>% html_text2()
test_department
```

Enfin, pour le nom du directeur ou de la directrice de recherche,
nous devons utiliser le sélecteur `#advisor1 p` :

```{r}
test_direction <- test_html %>% html_element("#advisor1 p") %>% html_text2()
test_direction
```

{{<ex>}}
Exercice - Extraire le titre "Abstract" et le texte de tous ses paragraphes
{{</ex>}}

Voici la solution attendue, soit une seule longue chaîne de caractères :
```{r}
#| echo: false
test_abstract <- test_html %>% html_element("#abstract") %>% html_text2()
"Abstract\n\n..."
```

Maintenant que nous avons nos trois informations, nous pouvons créer un tuple
avec ces trois valeurs en les passant comme arguments à la fonction `cbind()` :

```{r}
test_resultat <- cbind(test_date, test_department, test_direction)
test_resultat
```

### Extracting all links

Now that we have tested our code on the first dissertation, we can apply it on all 100 dissertations of the first page of the database.

Instead of using `html_element()`, this time we will use `html_elements()` which extracts *all* matching elements (instead of just the first one):

```{r}
dat <- html %>% html_elements(".article-listing")
dat
```

```{r}
typeof(dat)
length(dat)
typeof(dat[[1]])
```

We now have a list of lists.

As we did for a single link, we want to extract all the links to have a list of links. We will do this using a loop.

Before running for loops, it is important to initialize empty loops. It is much more efficient than growing the result at each iteration.

So let's initialize an empty list:

```{r}
list_links <- vector("list", length(dat))
```

Let's have a look at one element of our list (the second one for instance):

```{r}
list_links[[2]]
```

We now have an empty list of the appropriate size. We can run our loop:

```{r}
for (i in seq_along(dat)) {
  list_links[[i]] <- dat[[i]] %>%
    html_element("a") %>%
    html_attr("href")
}
```

Let's print again the second element of our list to make sure all looks good:

```{r}
list_links[[2]]
```

We have a character vector with one link. That's great! `list_links` is a list of links (in the form of character vectors) as we wanted.

### Getting the data from the list of links

We will now extract the data (date, major, and PI) for all links in our list.

Again, before running a for loop, we need to allocate memory first by creating an empty container:

```{r}
list_data <- vector("list", length(list_links))
```

We move the code we tested for a single dissertation inside a loop and we add one result to the `list_data` list at each iteration until we have all 100 dissertation sites scraped. Because there are quite a few of us running the code at the same time, we don't want the site to block our request. To play safe, we will add a little delay (0.1 second) at each iteration:

```{.r}
for (i in seq_along(list_links)) {
  html <- read_html(list_links[[i]])
  date <- html %>%
    html_element("#publication_date p") %>%
    html_text2()
  major <- html %>%
    html_element("#department p") %>%
    html_text2()
  pi <- html %>%
    html_element("#advisor1 p") %>%
    html_text2()
  Sys.sleep(0.1)  # Add a little delay
  list_data[[i]] <- cbind(date, major, pi)
}
```

Let's make sure all looks good by printing the second element of `list_data`:

```{r}
list_data[[2]]
```

All looking good, so let's turn this big list into a dataframe:

```{r}
result <- do.call(rbind.data.frame, list_data)
```

`result` is a long dataframe, so we will only print the first few elements:

```{r}
head(result)
```

If you like the tidyverse, you can turn it into a tibble:

```{r}
result <- result %>% tibble::as_tibble()
```

:::{.note}

The notation `tibble::as_tibble()` means that we are using the function `as_tibble()` from the package [tibble](https://tibble.tidyverse.org/). A tibble is the [tidyverse](https://www.tidyverse.org/) version of a dataframe. One advantage is that it will only print the first 10 rows by default instead of printing the whole dataframe, so you don't have to use `head()` when printing long dataframes:

```{r}
result
```

:::

We can rename the headers:

```{r}
names(result) <- c("Date", "Major", "PI")
```

This is what our final result looks like:

```{r}
result
```

## Points à retenir

**Les sélecteurs CSS :**

|   Sélecteurs    | Recherche pour ... |
|-----------------|--------------------|
| `balise`        | Tous les éléments de ce type de balise |
| `.classe`       | Tous les éléments ayant cette classe |
| `balise.classe` | Tous les éléments de ce type de balise ayant cette classe |
| `#identifiant`  | L'élément ayant cet identifiant unique |
| `#id balise`   | Tous les éléments de ce type de balise avec le parent `id` |

* Référence :
  [W3C - Selectors](https://www.w3.org/TR/selectors/#overview){target="_blank"}

**Les fonctions du module `rvest` :**

|     Fonctions     | Pour obtenir ... |
|-------------------|------------------|
| `html_attr()`     | La valeur d'un attribut |
| `html_children()` | Les éléments enfant |
| `html_element()`  | Le premier élément selon les sélecteurs CSS |
| `html_elements()` | Tous les éléments selon les sélecteurs CSS |
| `html_text2()`    | Le texte de l'élément |
| `read_html()`     | Le code HTML d'une page |

* Référence :
  [rvest - Function reference](https://rvest.tidyverse.org/reference/index.html){target="_blank"}
